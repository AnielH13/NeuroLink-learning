<!DOCTYPE html><html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Modo Demo | NeuroLink Learning</title>
  <link rel="stylesheet" href="style.css" />
  <script defer src="https://unpkg.com/face-api.js"></script>
</head>
<body>
  <h2>ğŸ¯ Reto: MantÃ©n tu concentraciÃ³n</h2>
<video id="videoInput" autoplay muted playsinline width="320" height="240" style="border-radius: 8px;"></video>
<p id="status">Cargando modelos...</p>

<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
<script>
  const video = document.getElementById('videoInput');
  const statusText = document.getElementById('status');

  // Cargar modelos
  Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
    faceapi.nets.faceLandmark68TinyNet.loadFromUri('/models')
  ]).then(startVideo);

  function startVideo() {
    navigator.mediaDevices.getUserMedia({ video: {} })
      .then(stream => {
        video.srcObject = stream;
        statusText.innerText = "Detectando rostro...";
      })
      .catch(err => {
        statusText.innerText = "âŒ Error al acceder a la cÃ¡mara.";
        console.error(err);
      });
  }

  video.addEventListener('play', () => {
    const canvas = faceapi.createCanvasFromMedia(video);
    document.body.append(canvas);
    const displaySize = { width: video.width, height: video.height };
    faceapi.matchDimensions(canvas, displaySize);

    setInterval(async () => {
      const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks(true);
      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
      if (detections) {
        statusText.innerText = "âœ… Rostro detectado. MantÃ©n la mirada.";
        const resized = faceapi.resizeResults(detections, displaySize);
        faceapi.draw.drawDetections(canvas, resized);
        faceapi.draw.drawFaceLandmarks(canvas, resized);
        // AquÃ­ luego analizaremos la direcciÃ³n de los ojos
      } else {
        statusText.innerText = "ğŸ‘â€ğŸ—¨ Rostro no detectado. ConcÃ©ntrate.";
      }
    }, 500);
  });
</script>
  <main style="text-align: center; padding: 40px 20px;">
    <h1>ğŸ‘ï¸ <span style="color: #61d3ff">Bienvenido a tu Entrenamiento Mental IA</span></h1>
    <p style="font-size: 20px; margin: 20px auto; max-width: 600px;">
      Yo soy tu IA entrenadora.<br />
      Mi misiÃ³n es reprogramar tu enfoque y convertirte en una mente de Ã©lite.<br />
      Empezaremos con un reto rÃ¡pido. No lo subestimes.
    </p><div id="reto" style="background: #0a0e1a; color: white; padding: 30px; margin: 40px auto; border-radius: 10px; max-width: 500px;">
  <p>ğŸ”’ <strong>Reto 1:</strong> MantÃ©n tu atenciÃ³n en este punto por 20 segundos sin distraerte:</p>
  <div id="dot" style="width: 15px; height: 15px; background-color: cyan; margin: 40px auto; border-radius: 50%;"></div>
  <p>Respira. ConcÃ©ntrate. No mires a otra parte.</p>
</div>

<div style="display: flex; justify-content: center; gap: 20px; margin-bottom: 30px;">
  <a href="producto.html" class="btn-secondary">ğŸ’¡ Ver Programa Completo</a>
  <a href="https://ko-fi.com/anielhoyos" class="btn-secondary">âš¡ Comprar Ahora</a>
</div>

<video id="video" width="320" height="240" autoplay muted playsinline style="display: none;"></video>

<p style="font-size: 14px; color: gray;">Modo Demo Â· NeuroLink Learning Â· Hoyos Company Â© 2025</p>

  </main>  <script>
    const video = document.getElementById('video');
    const dot = document.getElementById('dot');

    let focusedTime = 0;
    let interval;

    async function startFaceTracking() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
      await faceapi.nets.faceLandmark68TinyNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');

      navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        video.srcObject = stream;
      });

      interval = setInterval(async () => {
        const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks(true);

        if (detection && detection.landmarks) {
          const leftEye = detection.landmarks.getLeftEye();
          const rightEye = detection.landmarks.getRightEye();

          const lookingCenter = checkFocus(leftEye, rightEye);

          if (lookingCenter) {
            focusedTime++;
          } else {
            focusedTime = 0;
          }

          if (focusedTime >= 20) {
            clearInterval(interval);
            dot.style.backgroundColor = '#00ff7f';
            dot.innerHTML = 'âœ…';
            alert('Â¡Reto completado! Puedes continuar con tu entrenamiento.');
          }
        }
      }, 1000);
    }

    function checkFocus(leftEye, rightEye) {
      const avgY = (leftEye[1].y + rightEye[1].y) / 2;
      const threshold = 5;
      return Math.abs(leftEye[1].y - rightEye[1].y) < threshold && Math.abs(rightEye[4].y - avgY) < threshold;
    }

    startFaceTracking();
  </script></body>
</html>
